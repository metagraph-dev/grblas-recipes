{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c67ec2-3ad0-4a3f-b9e2-460ccc3d1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from grblas import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2953f-dfcf-4edf-b532-37496a65ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = io.mmread('geolocation.mtx').dup(int)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86265942-03bc-4c0c-9fa4-83329335e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.isequal(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a1110-ca35-4f84-be0a-635f4f0bf152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample.labels\n",
    "label_data = [\n",
    "    [1, 37.7449063493, -160.009432884],\n",
    "    [2, 37.8668048274, -130.797325311],\n",
    "    [3, 63.6431858915, -112.816156983],\n",
    "    [4, 51.6431858915, -172.816156983],\n",
    "    [5, 21.8691125061, -133.259106041],\n",
    "    [6, 55.6431858915, -177.816156983],\n",
    "    [7, 63.8652346572, -131.250634008],\n",
    "    [8, 61.2043433677, -114.300341275],\n",
    "    [13, 37.8691125062, -122.259106043],\n",
    "    [14, 30.8691125062, -100.259106043],\n",
    "    [15, 17.1211125062, -112.259106043],\n",
    "    [17, -37.8691125062, 122.259106043],\n",
    "    [18, 60.2043433677, -110.300341275],\n",
    "    [21, 86.8804435732, -170.640705659],\n",
    "    [22, 37.8804435732, -110.640705659],\n",
    "    [25, 38.2043433677, -114.300341275],\n",
    "    [28, 61.2043433677, -114.300341275],\n",
    "    [30, 37.8691125062, -122.259106043],\n",
    "    [31, 37.6431858915, -121.816156983],\n",
    "    [32, 37.8652346572, -122.250634008],\n",
    "    [33, 38.2043433677, -114.300341275],\n",
    "    [34, 36.7582225593, -118.167916598],\n",
    "    [35, 33.9774659389, -114.886512278],\n",
    "    [36, 39.2598884729, -106.804662071],\n",
    "    [37, 37.8804435732, -122.230147039],\n",
    "    [39, 9.42761644853, -110.640705659],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707457a-4dba-489d-99e9-95d96404df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations.labels\n",
    "label_data = [\n",
    "    [1, 37.7449063493, -122.009432884],\n",
    "    [2, 37.8668048274, -122.257973253],\n",
    "    [4, 37.869112506, -122.25910604],\n",
    "    [6, 37.6431858915, -121.816156983],\n",
    "    [11, 37.8652346572, -122.250634008],\n",
    "    [19, 38.2043433677, -114.300341275],\n",
    "    [21, 36.7582225593, -118.167916598],\n",
    "    [22, 33.9774659389, -114.886512278],\n",
    "    [30, 39.2598884729, -106.804662071],\n",
    "    [31, 37.880443573, -122.230147039],\n",
    "    [39, 9.4276164485, -110.640705659],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d3c74d-d68c-45c1-a8cb-198e7f9a3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 1000  # max iter in spatial median\n",
    "eps = 0.001  # epsilon check in spatial median\n",
    "max_mad = 1500.  # The sample data is probably pretty spread out, so we're using a very large value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb674d6-6507-4aab-b5e6-26dcf047615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(many_lat, many_lon, single_lat, single_lon, *, radius=6371.0, to_radians=True):\n",
    "    \"\"\"Compute the distances between many_{lat,lon} and single_{lat,lon}\"\"\"\n",
    "    # many_lat (and many_lon) may be a Matrix or a Vector\n",
    "    # single_lat (and single_lon) must be a Vector\n",
    "    if to_radians:\n",
    "        many_lat = op.numpy.radians(many_lat)\n",
    "        many_lon = op.numpy.radians(many_lon)\n",
    "        single_lat = op.numpy.radians(single_lat)\n",
    "        single_lon = op.numpy.radians(single_lon)\n",
    "    if utils.output_type(many_lat) is Vector:\n",
    "        diff_lat = op.minus(single_lat & many_lat)\n",
    "        diff_lon = op.minus(single_lon & many_lon)\n",
    "        cos_terms = op.times(op.cos(single_lat) & op.cos(many_lat))\n",
    "    else:\n",
    "        single_lat = ss.diag(single_lat)\n",
    "        single_lon = ss.diag(single_lon)\n",
    "        diff_lat = op.any_minus(single_lat @ many_lat)\n",
    "        diff_lon = op.any_minus(single_lon @ many_lon)\n",
    "        cos_terms = op.any_times(op.cos(single_lat) @ op.cos(many_lat))\n",
    "    a = op.plus(\n",
    "        op.sin(0.5 * diff_lat)**2\n",
    "        & op.times(cos_terms & op.sin(0.5 * diff_lon)**2)\n",
    "    )\n",
    "    return (2 * radius * op.asin(op.sqrt(a))).new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d0f73-cb72-44b9-a88d-9b6f5fa4cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# https://www.igismap.com/haversine-formula-calculate-geographic-distance-earth/\n",
    "# Nebraska\n",
    "v1 = Vector.from_values([0], [41.507483])\n",
    "w1 = Vector.from_values([0], [-99.436554])\n",
    "# Kansas\n",
    "v2 = Vector.from_values([0], [38.504048])\n",
    "w2 = Vector.from_values([0], [-98.315949])\n",
    "\n",
    "haversine_distance(v1, w1, v2, w2)[0].new().isclose(347.3, abs_tol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3ca3f7-2e46-4b77-a02c-475ead88d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, lat, lon = zip(*label_data)\n",
    "indices = [idx - 1 for idx in indices]  # change from 1-based to 0-based\n",
    "lat = Vector.from_values(indices, lat, size=A.nrows)\n",
    "lon = Vector.from_values(indices, lon, size=A.nrows)\n",
    "assert (op.abs(lat) <= 90).reduce(op.land)\n",
    "assert (op.abs(lon) <= 180).reduce(op.land)\n",
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38974174-923c-4e74-aa66-4d5aa9737e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to try to compute locations for these nodes\n",
    "unknown = Vector.new(int, size=lat.size)\n",
    "unknown(~lat.S) << 1\n",
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9361b-10ab-4df8-9b88-6965ae284b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = op.any_second(ss.diag(unknown) @ A).new()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2215f9ae-de5d-4cdd-862c-88008ea2af63",
   "metadata": {},
   "source": [
    "## Outer loop\n",
    "By default, do three iterations (or so).\n",
    "\n",
    "**Partition edges of unknown locations based on number of neighbors with locations: 1, 2, >2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76c298-e805-4862-9d2f-3fc09c075e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ulat = op.any_second(U @ ss.diag(lat)).new()\n",
    "Ulon = op.any_second(U @ ss.diag(lon)).new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db075883-8c88-44e6-8e4c-37d5559132e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = Ulat.reduce_rowwise(agg.count).new(dtype=int)\n",
    "min_degrees = degrees.reduce(op.min).new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7152842-261f-49ee-b8cb-a4d9961c9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "if min_degrees == 1:\n",
    "    # one_neighbor = select(degrees, 'EQ_THUNK', 1)\n",
    "    one_neighbor = (degrees == 1).new()\n",
    "    one_neighbor = one_neighbor.dup(int, mask=one_neighbor.V)\n",
    "else:\n",
    "    one_neighbor = Vector.new(int, size=degrees.size)\n",
    "one_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de72742-28d8-4ae2-8a97-b8c5fe737bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if min_degrees.value <= 2:\n",
    "    # two_neighbors = select(degrees, 'EQ_THUNK', 2)\n",
    "    two_neighbors = (degrees == 2).new()\n",
    "    two_neighbors = two_neighbors.dup(int, mask=two_neighbors.V)\n",
    "else:\n",
    "    two_neighbors = Vector.new(int, size=degrees.size)\n",
    "two_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a8827-8c9a-4db3-b74f-5088ecd212f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if min_degrees.value > 2:\n",
    "    # Unused.  We can use Ulat and Ulon directly\n",
    "    many_neighbors = unknown\n",
    "else:\n",
    "    # many_neighbors = select(degrees, 'GT_THUNK', 2)\n",
    "    many_neighbors = (degrees > 2).new()\n",
    "    many_neighbors = many_neighbors.dup(int, mask=many_neighbors.V)\n",
    "many_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180dcea6-be54-4b23-a142-29e46309ab99",
   "metadata": {},
   "source": [
    "**Compute where # neighbors == 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34d6e0-02dd-4bcd-b671-2289fd38455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median abs deviation\n",
    "mad = op.times(one_neighbor, 0.0).new()\n",
    "if one_neighbor.nvals > 0:\n",
    "    one_neighbor = ss.diag(one_neighbor)\n",
    "    lat(op.second) << op.any_second(one_neighbor @ Ulat).reduce_rowwise(op.any)\n",
    "    lon(op.second) << op.any_second(one_neighbor @ Ulon).reduce_rowwise(op.any)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b67e69-1730-4ca9-90d8-bbc4dbbf62dd",
   "metadata": {},
   "source": [
    "**Compute where # neighbors == 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8882f8-e55f-4ea3-858c-e9733f58bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if two_neighbors.nvals > 0:\n",
    "    two_neighbors = ss.diag(two_neighbors)\n",
    "    two_lat = op.any_second(two_neighbors @ Ulat).new()\n",
    "    two_lon = op.any_second(two_neighbors @ Ulon).new()\n",
    "\n",
    "    lat1 = two_lat.reduce_rowwise(agg.first).new()\n",
    "    lat2 = two_lat.reduce_rowwise(agg.last).new()\n",
    "    lon1 = two_lon.reduce_rowwise(agg.first).new()\n",
    "    lon2 = two_lon.reduce_rowwise(agg.last).new()\n",
    "\n",
    "    lat1 = op.numpy.radians(lat1).new()\n",
    "    lat2 = op.numpy.radians(lat2).new()\n",
    "    lon1 = op.numpy.radians(lon1).new()\n",
    "    lon2 = op.numpy.radians(lon2).new()\n",
    "\n",
    "    cos_lat2 = op.cos(lat2).new()\n",
    "    diff_lon = op.minus(lon2 & lon1).new()\n",
    "    bx = op.times(cos_lat2 & op.cos(diff_lon)).new()\n",
    "    by = op.times(cos_lat2 & op.sin(diff_lon)).new()\n",
    "    cos_lat1_bx = op.plus(op.cos(lat1) & bx).new()\n",
    "    lat3 = op.atan2(\n",
    "        op.plus(op.sin(lat1) & op.sin(lat2))\n",
    "        & op.hypot(cos_lat1_bx & by)\n",
    "    ).new()\n",
    "    lon3 = op.plus(lon1 & op.atan2(by & cos_lat1_bx)).new()\n",
    "    lat(op.second) << op.numpy.degrees(lat3)\n",
    "    lon(op.second) << op.numpy.degrees(lon3)\n",
    "\n",
    "    # Do we need to make sure lat is within -90 to 90, and lon is within -180 to 180?\n",
    "    assert (op.abs(lat3) <= np.pi / 2).reduce(op.land)\n",
    "    assert (op.abs(lon3) <= np.pi).reduce(op.land)\n",
    "    \n",
    "    # median abs deviation\n",
    "    mad(op.any) << haversine_distance(lat1, lon1, lat3, lon3, to_radians=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e39d40-5e16-43fe-a477-7359acd85ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if two_neighbors.nvals > 0:\n",
    "    # Sanity check\n",
    "    d1 = haversine_distance(lat1, lon1, lat3, lon3, to_radians=False)\n",
    "    d2 = haversine_distance(lat2, lon2, lat3, lon3, to_radians=False)\n",
    "    d12 = haversine_distance(lat1, lon1, lat2, lon2, to_radians=False)\n",
    "    assert d1.isclose(d2)\n",
    "    assert d12.isclose(d1 + d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39a5031-e2a9-49f4-9268-06d33339ced0",
   "metadata": {},
   "source": [
    "**Compute where # neighbors > 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08420aee-0336-4c5a-b3a4-86825ea0cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if many_neighbors.nvals == 0:\n",
    "    print('STOP!  No need to continue.  Start new iteration above.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda1702-50eb-42aa-a91f-41b2fde690a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if many_neighbors.nvals > 0:\n",
    "if one_neighbor.nvals == 0 and two_neighbors.nvals == 0:\n",
    "    many_lat = Ulat\n",
    "    many_lon = Ulon\n",
    "else:\n",
    "    many_neighbors = ss.diag(many_neighbors)\n",
    "    many_lat = op.any_second(many_neighbors @ Ulat).new()\n",
    "    many_lon = op.any_second(many_neighbors @ Ulon).new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4316f5-636c-4586-bc01-2b0c2fa013a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_lat = many_lat.reduce_rowwise(agg.mean).new()\n",
    "cur_lon = many_lon.reduce_rowwise(agg.mean).new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e0290-f014-435c-bd31-b4987b8066d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while True:\n",
    "    D = haversine_distance(many_lat, many_lon, cur_lat, cur_lon)\n",
    "    Dinv = op.minv(D).new(mask=D.V)  # drop 0s\n",
    "    Dinvs = Dinv.reduce_rowwise(op.plus).new()\n",
    "    W = op.any_rdiv(ss.diag(Dinvs) @ Dinv).new()\n",
    "\n",
    "    Tlat = op.times(many_lat & W).reduce_rowwise(op.plus).new()\n",
    "    Tlon = op.times(many_lon & W).reduce_rowwise(op.plus).new()\n",
    "\n",
    "    Dcounts = D.reduce_rowwise(agg.count[int]).new()\n",
    "    Dinv_counts = Dinv.reduce_rowwise(agg.count[int]).new()\n",
    "\n",
    "    num_zeros = op.minus(Dcounts & Dinv_counts).new()\n",
    "    # Other implementations partition the following calculations into three groups:\n",
    "    # if num_zeros == 0: cur_lat, cur_lon = Tlat, Tlon\n",
    "    # elif num_zeros == Dcounts: break\n",
    "    # else: r = ... ; alpha = ... ; next_lat = ... ;\n",
    "    #\n",
    "    # Let's simplify the calculation at the cost of doing a little more work\n",
    "\n",
    "    Rlat = op.times(op.minus(Tlat & cur_lat) & Dinvs).new()\n",
    "    Rlon = op.times(op.minus(Tlon & cur_lon) & Dinvs).new()\n",
    "    # r = op.sqrt(op.plus(Rlat**2 & Rlon**2)).new()\n",
    "    r = op.hypot(Rlat & Rlon).new()\n",
    "\n",
    "    # set rinv to 0 where divided by 0\n",
    "    rinv = op.truediv(num_zeros & r).new()\n",
    "    rinv(op.isinf(rinv).V) << 0.0\n",
    "    alpha = op.max(0.0, op.minus(1, rinv)).new()\n",
    "    beta = op.min(1.0, rinv).new()\n",
    "    next_lat = op.plus(\n",
    "        op.times(alpha & Tlat)\n",
    "        & op.times(beta & cur_lat)\n",
    "    ).new()\n",
    "    next_lon = op.plus(\n",
    "        op.times(alpha & Tlon)\n",
    "        & op.times(beta & cur_lon)\n",
    "    ).new()\n",
    "\n",
    "    if next_lat.nvals != cur_lat.nvals:\n",
    "        next_lat(op.first) << cur_lat\n",
    "        next_lon(op.first) << cur_lon\n",
    "\n",
    "    if i >= max_iter:\n",
    "        cur_lat = next_lat\n",
    "        cur_lon = next_lon\n",
    "        break\n",
    "\n",
    "    diff_lat = op.minus(cur_lat & next_lat).new()\n",
    "    diff_lon = op.minus(cur_lon & next_lon).new()\n",
    "    if (op.hypot(diff_lat & diff_lon) < eps).reduce(op.land).new():\n",
    "        # Once a node converges (either here or where num_zeros == Dcounts), we could\n",
    "        # remove it from future iterations.  Let's leave this as a future optimization.\n",
    "        cur_lat = next_lat\n",
    "        cur_lon = next_lon\n",
    "        break\n",
    "\n",
    "    cur_lat = next_lat\n",
    "    cur_lon = next_lon\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bc3e7-2b77-432d-a197-4e080acda87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (op.abs(cur_lat) <= 90).reduce(op.land)\n",
    "assert (op.abs(cur_lon) <= 180).reduce(op.land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e27f9-01d2-4610-ad7a-a78b109f4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat(op.second) << cur_lat\n",
    "lon(op.second) << cur_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4be8c-5df1-43cf-a89d-ee446c5e379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: This should actually use MEDIAN instead of MEAN!!!\n",
    "mad(op.any) << D.reduce_rowwise(agg.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2e665-02d7-4559-bcc9-add44c11867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop values with large absolute deviation\n",
    "mask = ~(mad > max_mad).V\n",
    "lat = lat.dup(mask=mask)\n",
    "lon = lon.dup(mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b3feb-cb87-4802-b4cb-06f784f5cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lat.nvals == lat.size:\n",
    "    print(\"All done!  We can stop early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26599d03-abce-4fa8-a03e-660b6a7bc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511093c-ddb6-4d1b-bdfe-b2528f908127",
   "metadata": {},
   "outputs": [],
   "source": [
    "mad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
